不得不说，看印度人写的英文就是爽，就像看汉语一样流畅，比美国人和英国人写的易读多了。

[1 引言]
    与传统特征提取方法提取特征描绘子不同，CNN可从图像中提取high-level的特征。受此启发，本文提出了一个基于深度学习的VO框架。利用CNN提取出的特征估算连续场景的位姿变换矩阵。本文的另一贡献是用单目视觉估计绝对尺度。由于训练网络可学习相机的内参和尺度，因此这种方法理论上具有可行性。

[2 相关工作]
    Optical flow between two images has been obtained by networks such as FlowNet [9] and EpicFlow [33]. Homography between two images have also been estimated using deep networks in [5].
    Agrawal et al. [1] 在特征学习中用ego-motion向量作为弱监督信。为了推断出ego-motion，他们在训练过程中将整个问题当作一个分类问题，而与此相反的是，我们将VO估计当作一个回归问题(regression problem)。

[3 方法论]
    算法的整个流程可分为两大部分：数据预处理和CNN框架。

A. 数据预处理
    我们用KITTI数据集做训练。由于本方法以单目为主，因此我们考虑使用单目相机拍摄的图像序列来训练。在KITTI的21个数据集中，有11个带有ground truth轨迹的数据集，我们用它们来训练和测试。原始的ground truth位姿数据是一系列表征从0时刻到t时刻的3X4位姿变换矩阵。我们对这些数据稍加处理，生成一种新的数据形式，它用于表示汽车平动的微分变化(∆x, ∆z, ∆Θ)。具体来说，是表征图像I_t到I_(t+1)在坐标轴(x,z)上的变化情况。由于我们的方法受AlexNet[21]的启发而提出，而AlexNet只接受正方形的图像，因此需要将KITTI数据集中1241×376的原始图像拉伸、降采样为256×256大小。之后，生成t到t+1时刻的图像对。因此，最终数据集的格式可表示为：
{ I_t, I_(t+1), (∆x,∆z,∆Θ)_[t−>(t+1)] }
    以上是输入图像和ground truth数据的标注格式。对于不同的实验，base数据应根据情况转换为更合理的格式，或加入额外的数据，下面的章节中将就此讨论。

B. 软硬件装备
CPU：Intel Xeon @4 x 3.3 GHZ
GPU：NVIDIA GTX 970
深度学习平台：Caffe
编程语言：Python

C. 深度学习框架



















