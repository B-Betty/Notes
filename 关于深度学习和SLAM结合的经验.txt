网址：

百度深度学习实验室：
http://idl.baidu.com/index.html

深度学习结合SLAM的研究思路/成果整理之（一）使用深度学习方法替换SLAM中的模块：
http://blog.csdn.net/u010821666/article/details/78749356

深度学习结合SLAM的研究思路/成果整理之（二）语义SLAM & 端到端：
http://blog.csdn.net/u010821666/article/details/78793225

---------------------------------------------------------
综述：

    截止到目前，就现在的论文研究水平和实际应用效果来看，绝大部分的深度学习+SLAM的文章都没有实际的应用价值，尤其是端到端(end-to-end)的CNN框架。端到端的深度学习SLAM框架目前只具有理论研究价值、容易发文章，因此有很多科研工作者去研究它。端到端的深度学习SLAM在已知场景和数据集上的表现和经典SLAM的精度相当，在某些情况下甚至超越了经典SLAM。但是一旦切换到未知场景或场景变化较大的场合，端到端的深度学习SLAM可以说毫无精度可言。特别是对于周廷辉的Unsupervised learning for depth and ego-motion from video这类无监督学习的文章，实际泛化的效果更值得怀疑。无监督学习目前只适合用于类别较少、且类间区别明显的分类问题，像这种对精度要求较高的位姿估计、特别是稠密深度图这种数据量很大的估计，无监督学习目前是不擅长的。
    这是因为深度学习更适合做检测、识别、分类、理解、语义、分割等高级特征信息的处理，而对tracking、位姿估计、mapping这种偏几何的事情不擅长。在经典SLAM框架中，每一步都是有章可循、有公式可以理解的，也知道怎么去改动相应的部分来改善SLAM整体的效果。相反地，用了深度学习后，它反而把原本清晰明了的逻辑结构弄得说不清了。到头来只是一个端到端的系统，中间是一个黑箱。
    知乎网友评论：个人觉得这种偏计算几何的问题还是不要用深度学习，深度学习适合高层理解。但是如果我们能搞明白高层理解的机制，那么深度学习也不具备优势了。
    如何结合深度学习与SLAM？高博已经介绍了很多，大概就是两条路。一是（部分地）替换现有模型，二是增加语义信息。学pose如果效果不好，可以像Magic leap那样用DL进行特征提取与跟踪，方法比现有人工设计的特征提取与跟踪算法都要优秀。

另，有一篇我很感兴趣的论文，不过跟SLAM没有结合，亮点在于街景的语义分割
Pohlen T, Hermans A, Mathias M, et al. Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes[J]. 2016.
用于街景语义分割的全分辨率残差网络
作者开放了源代码～～https://github.com/TobyPDE/FRRN

---------------------------------------------------------
想法1：经典SLAM做tracking + DL生成深度图
    印度理工的DeepVO提出用CNN来归回位姿估计，它是把t和t+1时刻的图像I_t、I_(t+1)即两帧之间的相对位姿变化(∆x,∆z,∆Θ)(ground truth)来训练一个CNN网络，即数据形式是：
      { I_t, I_(t+1), (∆x,∆z,∆Θ)_[t−>(t+1)] }
之后在测试时，输入的是视频流，输出的是两帧图像的位姿变化(∆x,∆z,∆Θ)。印度理工的DeepVO是将VO做成了一个端到端的深度学习框架。
    更进一步地看，其他的一些论文将整个SLAM设计成了一个端到端的深度学习框架。输入的是I_t、I_(t+1)，输出的是(∆x,∆z,∆Θ)_[t−>(t+1)]和深度图(mapping)。
    但之前的讨论也说过，用深度学习做位姿估计Tcw的效果是很差的，而稠密地图、深度图的重建需要Tcw的准确估计。因此，如果我们用经典的SLAM执行tracking得到比较准确的Tcw，再用：
      位姿Tcw + {I_t, I_(t+1)} →  深度图/稠密地图
的框架来得到深度图/稠密地图，可能效果更好。至于生成深度图的方法，既可用朴素的、传统的几何方法，也可以用新型的深度学习方法。举几个深度学习的例子：

1. CNN-SLAM
    CNN-SLAM这篇文章是用直接法(LSD-SLAM)和CNN结合的产物，它尝试着将经典SLAM和DL这两者的优势结合起来，但它的结合方法显得很生硬。算法首先划分为两个并行的模块，一是CNN生成深度图，二是SLAM得到位姿Tcw；之后再将两部分信息融合，具体做法是利用Tcw去优化深度图，共优化了两次。
    这种操作有几个缺点：一是深度图的产生和位姿的估计是完全独立的，但它们在逻辑上、以及几何物理意义上都是密不可分的；二是产生深度图时，CNN只用了单张图片的信息，即通过单张图片来估计场景深度。这在学术上似乎是和big clean的课题，符合研究者的审美，很有兴趣研究，但实际上只要简单想想就能隐约感觉到这种方法是多么可笑，缺乏明确的物理意义和推理逻辑，不靠谱。任何对场景的理解和深度估计，至少需要两幅图才能完成；三是两个模块的信息融合得很生硬，仅通过两组公式就融合了，没有太多明确的物理意义和数学优化理论的影子。
    这3种不足对应了3种改进的方法：在开始时就二者结合；利用多张图片（历史信息）做深度估计，甚至可以考虑RNN；寻求更自然的融合方式。
    另外，CNN-SLAM用的是直接法(基于LSD-SLAM)做位姿估计，直接法有它的好处，也有它的局限。可以考虑用特征点法(ORB)或半直接法(又称稀疏直接法，如SVO、DSO，它兼顾了直接法和特征点法的优势)来估计位姿。

2. Sparse-to-Dense
    这篇文章的全称是Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image. 它最突出的特点就是在中间过程中生成了一张稀疏深度图(sparse depth)，然后用这个稀疏深度图通过CNN生成一张稠密的深度图。实际操作的效果是：如果稀疏深度图用论文的方式生成，则CNN生成的稠密深度图效果不太好。而如果用精度不错的SLAM来生成稀疏深度图，那么生成的深度图效果会改善很多。

3. 单目+VIO/绝对尺度标定+SLAM+深度学习
    可以通过IMU（精度要高）或车速得到帧间位移的绝对尺度，来提高SLAM的精度。SLAM输出位姿估计后，再结合之前讨论的深度学习方法生成深度图，实现更好的效果。

























